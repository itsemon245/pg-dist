#!/usr/bin/env bash
set -euo pipefail

usage() {
  cat <<'USAGE'
setup_citus_cluster.sh
  Generates .env, docker-compose.yml, and init SQL for a Citus coordinator/workers cluster.
  It can also prompt interactively for missing values.

Flags:
  --with-coordinator        Include a coordinator service (default: off unless provided)
  --port=5432               Coordinator host port to expose (base for workers, which increment)
  --user=postgres           Postgres username (same for all nodes)
  --pass=<password>         Postgres password (same for all nodes)
  --workers=1               Number of workers to generate (1..N)
  -h | --help               Show this help

Examples:
  ./setup_citus_cluster.sh --with-coordinator --workers=2
  ./setup_citus_cluster.sh --with-coordinator --user=pg --pass=secret --port=6432 --workers=3
USAGE
}

# Defaults
WITH_COORD=0
BASE_PORT=5432
POSTGRES_USER="postgres"
POSTGRES_PASSWORD=""
WORKERS=1
POSTGRES_DB="postgres"
COORD_NAME="citus-coordinator"

# Parse flags
for arg in "$@"; do
  case $arg in
    --with-coordinator) WITH_COORD=1 ;;
    --port=*) BASE_PORT="${arg#*=}" ;;
    --user=*) POSTGRES_USER="${arg#*=}" ;;
    --pass=*) POSTGRES_PASSWORD="${arg#*=}" ;;
    --workers=*) WORKERS="${arg#*=}" ;;
    -h|--help) usage; exit 0 ;;
    *) echo "Unknown flag: $arg"; usage; exit 1 ;;
  esac
done

# Prompts for missing inputs
read -r -p "Postgres username [${POSTGRES_USER}]: " _in || true
POSTGRES_USER="${_in:-$POSTGRES_USER}"

if [[ -z "${POSTGRES_PASSWORD}" ]]; then
  read -r -s -p "Postgres password [auto-generate]: " _pw || true
  echo
  if [[ -z "${_pw}" ]]; then
    if command -v openssl >/dev/null 2>&1; then
      POSTGRES_PASSWORD="$(openssl rand -base64 18 | tr -d '\n' | tr '/+=' '-_A' | cut -c1-24)"
    else
      POSTGRES_PASSWORD="$(head -c 32 /dev/urandom | base64 | tr -d '\n' | tr '/+=' '-_A' | cut -c1-24)"
    fi
    echo "Generated password: ${POSTGRES_PASSWORD}"
  else
    POSTGRES_PASSWORD="${_pw}"
  fi
fi

read -r -p "Coordinator host port [${BASE_PORT}]: " _p || true
BASE_PORT="${_p:-$BASE_PORT}"

read -r -p "Number of workers [${WORKERS}]: " _w || true
WORKERS="${_w:-$WORKERS}"

read -r -p "Include coordinator service? (y/N) " _c || true
if [[ "${_c:-}" =~ ^[Yy]$ ]]; then WITH_COORD=1; fi

# Write .env
ENV_FILE=".env"
if [[ -f "${ENV_FILE}" ]]; then
  read -r -p ".env exists. Overwrite? (y/N) " _ow || true
  if [[ ! "${_ow:-}" =~ ^[Yy]$ ]]; then
    echo "Keeping existing .env"
  else
    : > "${ENV_FILE}"
  fi
fi

if [[ ! -s "${ENV_FILE}" ]]; then
  cat > "${ENV_FILE}" <<ENV
# Generated by setup_citus_cluster.sh
POSTGRES_USER=${POSTGRES_USER}
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
POSTGRES_DB=${POSTGRES_DB}
COORD_PORT=${BASE_PORT}
WORKERS=${WORKERS}
WITH_COORDINATOR=${WITH_COORD}
COORD_CONTAINER=${COORD_NAME}
ENV
  echo "Wrote ${ENV_FILE}"
fi

# Make init directories
mkdir -p initdb/coordinator initdb/worker

# Coordinator init SQL (runs once on first init)
cat > initdb/coordinator/01_citus.sql <<'SQL'
-- Runs inside the coordinator container on first init
CREATE EXTENSION IF NOT EXISTS citus;
-- Optional: set defaults cluster-wide later in a session or via ALTER SYSTEM
-- ALTER SYSTEM SET citus.shard_count = 64;
-- ALTER SYSTEM SET citus.shard_replication_factor = 1;
SELECT citus_version();
SQL

# Worker init SQL
cat > initdb/worker/01_citus.sql <<'SQL'
-- Runs inside each worker container on first init
CREATE EXTENSION IF NOT EXISTS citus;
SELECT citus_version();
SQL

# Generate docker-compose.yml
COMPOSE_FILE="docker-compose.yml"
echo "Generating ${COMPOSE_FILE} ..."

cat > "${COMPOSE_FILE}" <<'YAML'
version: "3.8"
services:
YAML

if [[ "${WITH_COORD}" -eq 1 ]]; then
cat >> "${COMPOSE_FILE}" <<'YAML'
  coordinator:
    image: citusdata/citus:13.0.3-pg15
    container_name: ${COORD_CONTAINER}
    ports:
      - "${COORD_PORT}:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Useful for psql connections initiated from inside the container
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./initdb/coordinator:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 30
    restart: unless-stopped
YAML
fi

# Workers
for i in $(seq 1 "${WORKERS}"); do
  WNAME="citus-worker${i}"
  HPORT=$(( BASE_PORT + i )) # workers on incremented host ports
  cat >> "${COMPOSE_FILE}" <<YAML
  worker${i}:
    image: citusdata/citus:13.0.3-pg15
    container_name: ${WNAME}
    environment:
      POSTGRES_USER: \${POSTGRES_USER}
      POSTGRES_PASSWORD: \${POSTGRES_PASSWORD}
      POSTGRES_DB: \${POSTGRES_DB}
      PGUSER: \${POSTGRES_USER}
      PGPASSWORD: \${POSTGRES_PASSWORD}
    ports:
      - "${HPORT}:5432"
    volumes:
      - ./initdb/worker:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U \${POSTGRES_USER} -d \${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 30
    restart: unless-stopped
YAML

  # If coordinator exists, ensure workers start after it
  if [[ "${WITH_COORD}" -eq 1 ]]; then
    # Append depends_on for the just-written worker service
    # (Simplest: sed append depends_on under the worker block)
    # Here we won't mutate; Docker will start fine in any order, but registration happens later anyway.
    :
  fi
done

echo "Wrote ${COMPOSE_FILE}"

cat <<NEXT

Done. Next steps:

1) Start containers:
   docker compose up -d

2) Check health:
   docker ps
   docker logs ${COORD_NAME} | tail -n +1

3) Register workers with the coordinator (after containers are healthy), one by one:
   ./add_worker_to_coordinator.sh --host citus-worker1 --port $((BASE_PORT+1))
   # repeat for worker2 as needed

Tip: the add_worker_to_coordinator.sh script reads credentials from .env.

NEXT
